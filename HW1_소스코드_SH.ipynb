{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1. MNIST 데이터셋을 활용해 다중 분류 수행하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제. 아래의 `코드`를 완성하고, 그에 대한 `분석`을 작성하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (코드) MNIST 데이터셋 받기\n",
    "   - (분석) 데이터셋에 대해 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리 import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터의 형태: (70000, 784)\n",
      "레이블의 형태: (70000,)\n",
      "\n",
      "레이블 값: [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "\n",
      "label 0 : 6903개\n",
      "label 1 : 7877개\n",
      "label 2 : 6990개\n",
      "label 3 : 7141개\n",
      "label 4 : 6824개\n",
      "label 5 : 6313개\n",
      "label 6 : 6876개\n",
      "label 7 : 7293개\n",
      "label 8 : 6825개\n",
      "label 9 : 6958개\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, y = mnist['data'], mnist['target'].astype(np.uint8)\n",
    "\n",
    "print(\"데이터의 형태:\", X.shape)\n",
    "print(\"레이블의 형태:\", y.shape)\n",
    "\n",
    "# 레이블의 값 출력\n",
    "labels = np.unique(y)\n",
    "print(\"\\n레이블 값:\", labels)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 레이블에 해당하는 데이터 수 출력\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "label_counts = dict(zip(unique, counts))\n",
    "\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"label {label} : {count}개\")\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST Dataset 분석 \n",
    "\n",
    "MNIST 에는 70000개의 이미지 데이터가 있으며 target은 0부터 9까지의 값으로 구성되어 있다.\n",
    "\n",
    "이미지는 28 * 28 픽셀의 흑백 손글씨 숫자로 구성되어 있으며, 확인한대로 28 * 28 = 784 개의 픽셀 데이터가 들어있다.\n",
    "각 이미지는 0부터 9까지의 숫자중 하나를 나타내고, label에 속하는 데이터의 갯수는 위와 같았다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (코드) 데이터셋을 train / validation / test set 으로 분할하기\n",
    "   - (분석) 데이터셋을 분할한 방식에 대해 설명하고, 해당 분할 방식을 수행한 이유에 대해 설명하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "X, y = mnist['data'], mnist['target'].astype(np.uint8)\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (코드) 특성 스케일링을 이용한 데이터셋 전처리하기\n",
    "   - (분석) 스케일링을 수행한 방식에 대해 설명하고, 해당 스케일링을 수행한 이유에 대해 설명하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_split)\n",
    "X_val_scaled = scaler.transform(X_val_split)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (코드) 모델 선택하기\n",
    "   - (분석) 머신러닝 모델의 후보군들에 대해 설명하고, 후보군들 중 특정 모델이 대표 모델로 선택된 이유에 대해 설명하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 로지스틱 회귀 (Logistic Regression)\n",
    "로지스틱 회귀는 Binary Classfication(이진 분류)를 위해 사용되지만 Softmax Regression을 사용하면 다중 클래스 분류에도 사용이 가능하다.\n",
    "하지만 데이터의 선형 관계를 이용해 분석하는 로지스틱 회귀는 데이터가 비선형적인(4와 9의 유사성 등) MNIST에는 사용하기 부적합하다고 판단했다.\n",
    "\n",
    "2. kNN, 최근접이웃 (k-Nearest Neighbors) \n",
    "새로운 데이터를 가장 가까운 k개의 이웃의 class를 참조하여 분류하는 kNN 알고리즘을 이용해 분류할 수 있다.\n",
    "그러나 kNN은 새로운 데이터 포인트를 분류할 때 기존의 모든 데이터와의 거리를 계산해야 하므로, 데이터셋이 클수록 계산 비용이 급격히 증가하는 단점이 있다.\n",
    "또한 단순히 이웃의 class를 기반으로 분류를 결정하기 때문에, 분류 결과에 대한 직관적인 설명이 어렵다.\n",
    "Scikit learn 으로 구현한 사례가 존재한다. (https://teddylee777.github.io/scikit-learn/scikit-learn-knn/)\n",
    "\n",
    "3. CNN, 합성곱 신경망 (Convolutional Neural Networks)\n",
    "CNN은 이미지 분류 작업에서 매우 효과적인 알고리즘임을 확인할 수 있었다. 특히 데이터가 비선형적이거나 복잡한 패턴을 포함하고 있을 때 높은 성능을 보여주므로\n",
    "이번 Homework에는 MNIST를 분류하는데 CNN 모델을 이용하였다.\n",
    "\n",
    "//또한 수업시간에 다루었던 확률적 경사 하강 모델(SGD) , 랜덤포레스트 모델, 결정트리 모델을 이용해 MNIST를 분류해보고 CNN 모델과 비교해보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (코드) 성능 평가하기\n",
    "   - (분석) 최종적으로 학습된 모델을 이용해 test set 에 대한 성능을 정리하고, 이를 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "multilayerperceptron_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "multilayerperceptron_clf.fit(X_train_scaled,y_train_split)\n",
    "\n",
    "multilayer_val_score = multilayerperceptron_clf.score(X_val_scaled, y_val_split)\n",
    "multilayer_test_score = multilayerperceptron_clf.score(X_test_scaled, y_test)\n",
    "\n",
    "y_pred = multilayerperceptron_clf.predict(X_test)\n",
    "mtx_cf = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confution Matrix: \n",
      " [[ 975    0    0    1    1    0    1    1    1    0]\n",
      " [   0 1125    3    1    0    0    1    1    4    0]\n",
      " [   5    4 1003    2    0    0    5    5    7    1]\n",
      " [   1    0    4  992    0    2    0    4    0    7]\n",
      " [   2    1    1    1  954    0    4    5    2   12]\n",
      " [   3    1    0   15    3  855    7    1    2    5]\n",
      " [   5    2    1    1    3    2  943    0    1    0]\n",
      " [   0    4    6    2    2    0    0 1006    4    4]\n",
      " [   6    1    2   10    5    4    2    4  937    3]\n",
      " [   3    2    0    5    5    4    0    5    2  983]]\n",
      "Number of Samples: \t   10000 (100.00%)\n",
      "Number of Positive Labels:  9773 ( 97.73%)\n",
      "Number of Negative Labels:   227 (  2.27%)\n"
     ]
    }
   ],
   "source": [
    "print('Confution Matrix: \\n', mtx_cf)\n",
    "\n",
    "total_samples = mtx_cf.sum()\n",
    "num_positive = mtx_cf.diagonal().sum()\n",
    "num_negative = total_samples - num_positive\n",
    "\n",
    "print('Number of Samples: \\t  ',    f'{total_samples:5d}',    f'({total_samples / total_samples * 100:6.2f}%)')\n",
    "print('Number of Positive Labels:', f'{num_positive:5d}', f'({num_positive / total_samples * 100:6.2f}%)')\n",
    "print('Number of Negative Labels:', f'{num_negative:5d}', f'({num_negative / total_samples * 100:6.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "실행 결과 97.73%의 정확도를 보여주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:      Function ~ Confusion\n",
      "Accuracy:\t0.97394 ~ 1.0000\n",
      "Precision:\t0.97392 ~ 1.0000\n",
      "Recall:\t\t0.97394 ~ 1.0000\n",
      "F1:\t\t0.97393 - 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "TN = mtx_cf[0, 0]\n",
    "FP = mtx_cf[0, 1]\n",
    "FN = mtx_cf[1, 0]\n",
    "TP = mtx_cf[1, 1]\n",
    "\n",
    "func_acc = lambda mtx_cf: (mtx_cf[0, 0] + mtx_cf[1, 1]) / (mtx_cf[0, 0] + mtx_cf[0, 1] + mtx_cf[1, 0] + mtx_cf[1, 1])\n",
    "func_pre = lambda mtx_cf: (mtx_cf[1, 1]) / (mtx_cf[0, 1] + mtx_cf[1, 1])\n",
    "func_rec = lambda mtx_cf: (mtx_cf[1, 1]) / (mtx_cf[1, 0] + mtx_cf[1, 1])\n",
    "func_spe = lambda mtx_cf: (mtx_cf[0, 0]) / (mtx_cf[0, 0] + mtx_cf[0, 1])\n",
    "func_f1 = lambda precision, recall: 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "#교차검증을 위한 cross_validation 항목 추가\n",
    "y_train_pred = cross_val_predict(multilayerperceptron_clf, X_train_scaled, y_train_split, cv=5)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_train_split,y_train_pred)\n",
    "prec = precision_score(y_train_split,y_train_pred,average='weighted')\n",
    "recall = recall_score(y_train_split,y_train_pred,average='weighted')\n",
    "f1 = f1_score(y_train_split,y_train_pred,average='weighted')\n",
    "\n",
    "acc_ = func_acc(mtx_cf)\n",
    "prec_ = func_pre(mtx_cf)\n",
    "recall_ = func_rec(mtx_cf)\n",
    "f1_ = func_f1(prec_, recall_)\n",
    "\n",
    "spe_ = func_spe(mtx_cf)\n",
    "\n",
    "\n",
    "print(f\"Metrics:      Function ~ Confusion\")\n",
    "print(f\"Accuracy:\\t{acc:.5f} ~ {acc_:.4f}\")\n",
    "print(f\"Precision:\\t{prec:.5f} ~ {prec_:.4f}\")\n",
    "print(f\"Recall:\\t\\t{recall:.5f} ~ {recall_:.4f}\")\n",
    "print(f\"F1:\\t\\t{f1:.5f} - {f1_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "결과 분석\n",
    "\n",
    "Accuracy가 약 0.973 정도로 선택한 모델이 Test Set에서 올바르게 분류하고 있음을 알 수 있다.\n",
    "또한 정밀도와 재현률의 결과 또한 0.973으로 높은 성능을 보여주었고,\n",
    "F1 Score의 점수도 높아 정밀도와 재현율이 균형을 이루고 있음을 확인할 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (코드) 에러 분석하기\n",
    "   - (분석) 최종적으로 학습된 모델의 에러를 분석하기\n",
    "   - (분석) `5. 성능 평가하기` 의 분석과 연관지어 에러를 분석하고 해결책을 제안하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
